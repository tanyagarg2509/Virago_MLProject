{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = os.path.join('/Desktop',' cleaned_dataset_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_dataset_train.csv',sep=\",\")   ##comma seperated file :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunction. ...</td>\n",
       "      <td>#run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit can't use caus offer wheelc...</td>\n",
       "      <td>#lyft #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesti</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take time urd+-!!! dddd d|d|d|</td>\n",
       "      <td>#model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: societi #motiv</td>\n",
       "      <td>#motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[2/2] huge fan fare big talk leave. chao pay d...</td>\n",
       "      <td>#allshowandnogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camp tomorrow dannya|</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>next school year year exams.d- can't think #sc...</td>\n",
       "      <td>#school #exams #hate #imagine #actorslife #rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>won!!! love land!!! #allin #cav #champion #cle...</td>\n",
       "      <td>#allin #cavs #champions #cleveland #clevelandc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcom ! i'm #gr8 !</td>\n",
       "      <td>#gr8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "      <td>#ireland consum price index (mom) climb previo...</td>\n",
       "      <td>#ireland #blog #silver #gold #forex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "      <td>selfish. #orlando #standwithorlando #pulseshoo...</td>\n",
       "      <td>#orlando #standwithorlando #pulseshooting #orl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "      <td>get see daddi today!! #80day #gettingf</td>\n",
       "      <td>#80days #gettingfed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "      <td>#cnn call #michigan middl school 'build wall' ...</td>\n",
       "      <td>#cnn #michigan #tcot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "      <td>comment! #australia #opkillingbay #seashepherd...</td>\n",
       "      <td>#australia #opkillingbay #seashepherd #helpcov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "      <td>ouch...junior angryd#got7 #junior #yugyoem #omg</td>\n",
       "      <td>#junior #yugyoem #omg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "      <td>thank paner. #thank #posit</td>\n",
       "      <td>#thankful #positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>retweet agree!</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "      <td>#friday! smile around via ig user: #cooki make...</td>\n",
       "      <td>#friday! #cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "      <td>know, essenti oil made chemicals.</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>#euro2016 people blaming ha for conceded goal ...</td>\n",
       "      <td>#euro2016 peopl blame ha conced goal fat roone...</td>\n",
       "      <td>#euro2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>sad little dude..   #badday #coneofshame #cats...</td>\n",
       "      <td>sad littl dude.. #badday #coneofsham #cat #pis...</td>\n",
       "      <td>#badday #coneofshame #cats #pissed #funny #laughs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>product of the day: happy man #wine tool  who'...</td>\n",
       "      <td>product day: happi man #wine tool who' #weeken...</td>\n",
       "      <td>#wine #weekend?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
       "      <td>lumpi say . prove lumpy.</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>@user #tgif   #ff to my #gamedev #indiedev #i...</td>\n",
       "      <td>#tgif #ff #gamedev #indiedev #indiegamedev #sq...</td>\n",
       "      <td>#tgif #ff #gamedev #indiedev #indiegamedev #sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>beautiful sign by vendor 80 for $45.00!! #upsi...</td>\n",
       "      <td>beauti sign vendor $45.00!! #upsideofflorida #...</td>\n",
       "      <td>#upsideofflorida #shopalyssas #love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>@user all #smiles when #media is   !! ðð...</td>\n",
       "      <td>#smile #media !! dd #pressconfer #antalya #tur...</td>\n",
       "      <td>#smiles #media #pressconference #antalya #turk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>we had a great panel on the mediatization of t...</td>\n",
       "      <td>great panel mediat public servic #ica16</td>\n",
       "      <td>#ica16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>happy father's day @user ðððð</td>\n",
       "      <td>happi father' day dddd</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>50 people went to nightclub to have a good nig...</td>\n",
       "      <td>peopl went nightclub good night man' action me...</td>\n",
       "      <td>#rip#orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31932</th>\n",
       "      <td>31932</td>\n",
       "      <td>31933</td>\n",
       "      <td>0</td>\n",
       "      <td>@user thanks gemma</td>\n",
       "      <td>thank gemma</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31933</th>\n",
       "      <td>31933</td>\n",
       "      <td>31934</td>\n",
       "      <td>1</td>\n",
       "      <td>@user judd is a  &amp;amp; #homophobic #freemilo #...</td>\n",
       "      <td>judd &amp;amp; #homophob #freemilo #milo #freemilo...</td>\n",
       "      <td>#homophobic #freemilo #milo #freemilo #milo #f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31934</th>\n",
       "      <td>31934</td>\n",
       "      <td>31935</td>\n",
       "      <td>1</td>\n",
       "      <td>lady banned from kentucky mall. @user  #jcpenn...</td>\n",
       "      <td>ladi ban kentucki mall. #jcpenni #kentucki</td>\n",
       "      <td>#jcpenny #kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31935</th>\n",
       "      <td>31935</td>\n",
       "      <td>31936</td>\n",
       "      <td>0</td>\n",
       "      <td>ugh i'm trying to enjoy my happy hour drink &amp;a...</td>\n",
       "      <td>ugh i'm tri enjoy happi hour drink &amp;amp; talk ...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31936</th>\n",
       "      <td>31936</td>\n",
       "      <td>31937</td>\n",
       "      <td>0</td>\n",
       "      <td>want to know how to live a   life? do more thi...</td>\n",
       "      <td>want know live life? thing make happi le thing...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31937</th>\n",
       "      <td>31937</td>\n",
       "      <td>31938</td>\n",
       "      <td>0</td>\n",
       "      <td>love island ð</td>\n",
       "      <td>love island</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31938</th>\n",
       "      <td>31938</td>\n",
       "      <td>31939</td>\n",
       "      <td>0</td>\n",
       "      <td>my fav actor #vijaysethupathi ! my fav actress...</td>\n",
       "      <td>fav actor #vijaysethupathi ! fav actress ! fav...</td>\n",
       "      <td>#vijaysethupathi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31939</th>\n",
       "      <td>31939</td>\n",
       "      <td>31940</td>\n",
       "      <td>0</td>\n",
       "      <td>whew  ð",
       " it's a productive and   #friday!!!</td>\n",
       "      <td>whew product #friday!!!</td>\n",
       "      <td>#friday!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31940</th>\n",
       "      <td>31940</td>\n",
       "      <td>31941</td>\n",
       "      <td>0</td>\n",
       "      <td>@user she's finally here! @user</td>\n",
       "      <td>final here!</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31941</th>\n",
       "      <td>31941</td>\n",
       "      <td>31942</td>\n",
       "      <td>0</td>\n",
       "      <td>passed first year of uni #yay #love #pass #uni...</td>\n",
       "      <td>pass first year uni #yay #love #pass #unistud ...</td>\n",
       "      <td>#yay #love #pass #unistudent #photographystude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31942</th>\n",
       "      <td>31942</td>\n",
       "      <td>31943</td>\n",
       "      <td>0</td>\n",
       "      <td>this week is flying by   #humpday - #wednesday...</td>\n",
       "      <td>week fli #humpday - #wednesday #kamp #ucsda|</td>\n",
       "      <td>#humpday #wednesday #kamp #ucsda|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31943</th>\n",
       "      <td>31943</td>\n",
       "      <td>31944</td>\n",
       "      <td>0</td>\n",
       "      <td>@user modeling photoshoot this friday yay #mo...</td>\n",
       "      <td>model photoshoot friday yay #model #me #follow...</td>\n",
       "      <td>#model #me #follow #emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31944</th>\n",
       "      <td>31944</td>\n",
       "      <td>31945</td>\n",
       "      <td>0</td>\n",
       "      <td>you're surrounded by people who love you (even...</td>\n",
       "      <td>surround peopl love (even deserve) yet, hateful?</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31945</th>\n",
       "      <td>31945</td>\n",
       "      <td>31946</td>\n",
       "      <td>0</td>\n",
       "      <td>feel like... ðð¶ð #dog #summer #hot #h...</td>\n",
       "      <td>feel like... ddpd #dog #summer #hot #help #sun...</td>\n",
       "      <td>#dog #summer #hot #help #sun #day #more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31946</th>\n",
       "      <td>31946</td>\n",
       "      <td>31947</td>\n",
       "      <td>1</td>\n",
       "      <td>@user omfg i'm offended! i'm a  mailbox and i'...</td>\n",
       "      <td>omfg i'm offended! i'm mailbox i'm proud! #mai...</td>\n",
       "      <td>#mailboxpride #liberalisme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>31947</td>\n",
       "      <td>31948</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user you don't have the balls to hashta...</td>\n",
       "      <td>ball hashtag say weasel away.. lumpi tony.. di...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>31948</td>\n",
       "      <td>31949</td>\n",
       "      <td>1</td>\n",
       "      <td>makes you ask yourself, who am i? then am i a...</td>\n",
       "      <td>make ask yourself, i? anybody? ....god . oh th...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31949</th>\n",
       "      <td>31949</td>\n",
       "      <td>31950</td>\n",
       "      <td>0</td>\n",
       "      <td>hear one of my new songs! don't go - katie ell...</td>\n",
       "      <td>hear one new songs! go - kati elli #youtub #or...</td>\n",
       "      <td>#youtube #original #music #song #relationship ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31950</th>\n",
       "      <td>31950</td>\n",
       "      <td>31951</td>\n",
       "      <td>0</td>\n",
       "      <td>@user you can try to 'tail' us to stop, 'butt...</td>\n",
       "      <td>tri 'tail' u stop, 'butt' we'r good time! #gol...</td>\n",
       "      <td>#goldenretriever #animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31951</th>\n",
       "      <td>31951</td>\n",
       "      <td>31952</td>\n",
       "      <td>0</td>\n",
       "      <td>i've just posted a new blog: #secondlife #lone...</td>\n",
       "      <td>i'v post new blog: #secondlif #lone #neko</td>\n",
       "      <td>#secondlife #lonely #neko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31952</th>\n",
       "      <td>31952</td>\n",
       "      <td>31953</td>\n",
       "      <td>0</td>\n",
       "      <td>@user you went too far with @user</td>\n",
       "      <td>went far</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31953</th>\n",
       "      <td>31953</td>\n",
       "      <td>31954</td>\n",
       "      <td>0</td>\n",
       "      <td>good morning #instagram #shower #water #berlin...</td>\n",
       "      <td>good morn #instagram #shower #water #berlin #b...</td>\n",
       "      <td>#instagram #shower #water #berlin #berlincityg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31954</th>\n",
       "      <td>31954</td>\n",
       "      <td>31955</td>\n",
       "      <td>0</td>\n",
       "      <td>#holiday   bull up: you will dominate your bul...</td>\n",
       "      <td>#holiday bull up: domin bull direct whatev wan...</td>\n",
       "      <td>#holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31955</th>\n",
       "      <td>31955</td>\n",
       "      <td>31956</td>\n",
       "      <td>0</td>\n",
       "      <td>less than 2 weeks ð",
       "ðð¼ð¹ððµ @us...</td>\n",
       "      <td>le week dd 1/4 d1ddu #ibiza#bringiton#mallorca...</td>\n",
       "      <td>#ibiza#bringiton#mallorca#holidays#summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31956</th>\n",
       "      <td>31956</td>\n",
       "      <td>31957</td>\n",
       "      <td>0</td>\n",
       "      <td>off fishing tomorrow @user carnt wait first ti...</td>\n",
       "      <td>fish tomorrow carnt wait first time year</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31957</td>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate isz youuu?ddddddddda$?i,</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31958</td>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>see nina turner airwav tri wrap mantl genuin h...</td>\n",
       "      <td>#shame #imwithher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31959</td>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listen sad song monday morn otw work sad</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31960</td>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>#sikh #templ vandalis #calgary, #wso condemn act</td>\n",
       "      <td>#sikh #temple #calgary, #wso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31961</td>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank follow</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id  label  \\\n",
       "0               0      1      0   \n",
       "1               1      2      0   \n",
       "2               2      3      0   \n",
       "3               3      4      0   \n",
       "4               4      5      0   \n",
       "5               5      6      0   \n",
       "6               6      7      0   \n",
       "7               7      8      0   \n",
       "8               8      9      0   \n",
       "9               9     10      0   \n",
       "10             10     11      0   \n",
       "11             11     12      0   \n",
       "12             12     13      0   \n",
       "13             13     14      1   \n",
       "14             14     15      1   \n",
       "15             15     16      0   \n",
       "16             16     17      0   \n",
       "17             17     18      1   \n",
       "18             18     19      0   \n",
       "19             19     20      0   \n",
       "20             20     21      0   \n",
       "21             21     22      0   \n",
       "22             22     23      0   \n",
       "23             23     24      1   \n",
       "24             24     25      0   \n",
       "25             25     26      0   \n",
       "26             26     27      0   \n",
       "27             27     28      0   \n",
       "28             28     29      0   \n",
       "29             29     30      0   \n",
       "...           ...    ...    ...   \n",
       "31932       31932  31933      0   \n",
       "31933       31933  31934      1   \n",
       "31934       31934  31935      1   \n",
       "31935       31935  31936      0   \n",
       "31936       31936  31937      0   \n",
       "31937       31937  31938      0   \n",
       "31938       31938  31939      0   \n",
       "31939       31939  31940      0   \n",
       "31940       31940  31941      0   \n",
       "31941       31941  31942      0   \n",
       "31942       31942  31943      0   \n",
       "31943       31943  31944      0   \n",
       "31944       31944  31945      0   \n",
       "31945       31945  31946      0   \n",
       "31946       31946  31947      1   \n",
       "31947       31947  31948      1   \n",
       "31948       31948  31949      1   \n",
       "31949       31949  31950      0   \n",
       "31950       31950  31951      0   \n",
       "31951       31951  31952      0   \n",
       "31952       31952  31953      0   \n",
       "31953       31953  31954      0   \n",
       "31954       31954  31955      0   \n",
       "31955       31955  31956      0   \n",
       "31956       31956  31957      0   \n",
       "31957       31957  31958      0   \n",
       "31958       31958  31959      0   \n",
       "31959       31959  31960      0   \n",
       "31960       31960  31961      1   \n",
       "31961       31961  31962      0   \n",
       "\n",
       "                                                   tweet  \\\n",
       "0       @user when a father is dysfunctional and is s...   \n",
       "1      @user @user thanks for #lyft credit i can't us...   \n",
       "2                                    bihday your majesty   \n",
       "3      #model   i love u take with u all the time in ...   \n",
       "4                 factsguide: society now    #motivation   \n",
       "5      [2/2] huge fan fare and big talking before the...   \n",
       "6       @user camping tomorrow @user @user @user @use...   \n",
       "7      the next school year is the year for exams.ð...   \n",
       "8      we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9       @user @user welcome here !  i'm   it's so #gr...   \n",
       "10      â #ireland consumer price index (mom) climb...   \n",
       "11     we are so selfish. #orlando #standwithorlando ...   \n",
       "12     i get to see my daddy today!!   #80days #getti...   \n",
       "13     @user #cnn calls #michigan middle school 'buil...   \n",
       "14     no comment!  in #australia   #opkillingbay #se...   \n",
       "15     ouch...junior is angryð#got7 #junior #yugyo...   \n",
       "16     i am thankful for having a paner. #thankful #p...   \n",
       "17                                retweet if you agree!    \n",
       "18     its #friday! ð smiles all around via ig use...   \n",
       "19     as we all know, essential oils are not made of...   \n",
       "20     #euro2016 people blaming ha for conceded goal ...   \n",
       "21     sad little dude..   #badday #coneofshame #cats...   \n",
       "22     product of the day: happy man #wine tool  who'...   \n",
       "23       @user @user lumpy says i am a . prove it lumpy.   \n",
       "24      @user #tgif   #ff to my #gamedev #indiedev #i...   \n",
       "25     beautiful sign by vendor 80 for $45.00!! #upsi...   \n",
       "26      @user all #smiles when #media is   !! ðð...   \n",
       "27     we had a great panel on the mediatization of t...   \n",
       "28           happy father's day @user ðððð     \n",
       "29     50 people went to nightclub to have a good nig...   \n",
       "...                                                  ...   \n",
       "31932                               @user thanks gemma     \n",
       "31933  @user judd is a  &amp; #homophobic #freemilo #...   \n",
       "31934  lady banned from kentucky mall. @user  #jcpenn...   \n",
       "31935  ugh i'm trying to enjoy my happy hour drink &a...   \n",
       "31936  want to know how to live a   life? do more thi...   \n",
       "31937                                 love island ð     \n",
       "31938  my fav actor #vijaysethupathi ! my fav actress...   \n",
       "31939      whew  ð",
       " it's a productive and   #friday!!!   \n",
       "31940                 @user she's finally here! @user      \n",
       "31941  passed first year of uni #yay #love #pass #uni...   \n",
       "31942  this week is flying by   #humpday - #wednesday...   \n",
       "31943   @user modeling photoshoot this friday yay #mo...   \n",
       "31944  you're surrounded by people who love you (even...   \n",
       "31945  feel like... ðð¶ð #dog #summer #hot #h...   \n",
       "31946  @user omfg i'm offended! i'm a  mailbox and i'...   \n",
       "31947  @user @user you don't have the balls to hashta...   \n",
       "31948   makes you ask yourself, who am i? then am i a...   \n",
       "31949  hear one of my new songs! don't go - katie ell...   \n",
       "31950   @user you can try to 'tail' us to stop, 'butt...   \n",
       "31951  i've just posted a new blog: #secondlife #lone...   \n",
       "31952                @user you went too far with @user     \n",
       "31953  good morning #instagram #shower #water #berlin...   \n",
       "31954  #holiday   bull up: you will dominate your bul...   \n",
       "31955  less than 2 weeks ð",
       "ðð¼ð¹ððµ @us...   \n",
       "31956  off fishing tomorrow @user carnt wait first ti...   \n",
       "31957  ate @user isz that youuu?ðððððð...   \n",
       "31958    to see nina turner on the airwaves trying to...   \n",
       "31959  listening to sad songs on a monday morning otw...   \n",
       "31960  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961                   thank you @user for you follow     \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "0      father dysfunct selfish drag kid dysfunction. ...   \n",
       "1      thank #lyft credit can't use caus offer wheelc...   \n",
       "2                                         bihday majesti   \n",
       "3             #model love take time urd+-!!! dddd d|d|d|   \n",
       "4                             factsguide: societi #motiv   \n",
       "5      [2/2] huge fan fare big talk leave. chao pay d...   \n",
       "6                                  camp tomorrow dannya|   \n",
       "7      next school year year exams.d- can't think #sc...   \n",
       "8      won!!! love land!!! #allin #cav #champion #cle...   \n",
       "9                                    welcom ! i'm #gr8 !   \n",
       "10     #ireland consum price index (mom) climb previo...   \n",
       "11     selfish. #orlando #standwithorlando #pulseshoo...   \n",
       "12                get see daddi today!! #80day #gettingf   \n",
       "13     #cnn call #michigan middl school 'build wall' ...   \n",
       "14     comment! #australia #opkillingbay #seashepherd...   \n",
       "15       ouch...junior angryd#got7 #junior #yugyoem #omg   \n",
       "16                            thank paner. #thank #posit   \n",
       "17                                        retweet agree!   \n",
       "18     #friday! smile around via ig user: #cooki make...   \n",
       "19                     know, essenti oil made chemicals.   \n",
       "20     #euro2016 peopl blame ha conced goal fat roone...   \n",
       "21     sad littl dude.. #badday #coneofsham #cat #pis...   \n",
       "22     product day: happi man #wine tool who' #weeken...   \n",
       "23                              lumpi say . prove lumpy.   \n",
       "24     #tgif #ff #gamedev #indiedev #indiegamedev #sq...   \n",
       "25     beauti sign vendor $45.00!! #upsideofflorida #...   \n",
       "26     #smile #media !! dd #pressconfer #antalya #tur...   \n",
       "27               great panel mediat public servic #ica16   \n",
       "28                                happi father' day dddd   \n",
       "29     peopl went nightclub good night man' action me...   \n",
       "...                                                  ...   \n",
       "31932                                        thank gemma   \n",
       "31933  judd &amp; #homophob #freemilo #milo #freemilo...   \n",
       "31934         ladi ban kentucki mall. #jcpenni #kentucki   \n",
       "31935  ugh i'm tri enjoy happi hour drink &amp; talk ...   \n",
       "31936  want know live life? thing make happi le thing...   \n",
       "31937                                        love island   \n",
       "31938  fav actor #vijaysethupathi ! fav actress ! fav...   \n",
       "31939                            whew product #friday!!!   \n",
       "31940                                        final here!   \n",
       "31941  pass first year uni #yay #love #pass #unistud ...   \n",
       "31942       week fli #humpday - #wednesday #kamp #ucsda|   \n",
       "31943  model photoshoot friday yay #model #me #follow...   \n",
       "31944   surround peopl love (even deserve) yet, hateful?   \n",
       "31945  feel like... ddpd #dog #summer #hot #help #sun...   \n",
       "31946  omfg i'm offended! i'm mailbox i'm proud! #mai...   \n",
       "31947  ball hashtag say weasel away.. lumpi tony.. di...   \n",
       "31948  make ask yourself, i? anybody? ....god . oh th...   \n",
       "31949  hear one new songs! go - kati elli #youtub #or...   \n",
       "31950  tri 'tail' u stop, 'butt' we'r good time! #gol...   \n",
       "31951          i'v post new blog: #secondlif #lone #neko   \n",
       "31952                                           went far   \n",
       "31953  good morn #instagram #shower #water #berlin #b...   \n",
       "31954  #holiday bull up: domin bull direct whatev wan...   \n",
       "31955  le week dd 1/4 d1ddu #ibiza#bringiton#mallorca...   \n",
       "31956           fish tomorrow carnt wait first time year   \n",
       "31957                       ate isz youuu?ddddddddda$?i,   \n",
       "31958  see nina turner airwav tri wrap mantl genuin h...   \n",
       "31959           listen sad song monday morn otw work sad   \n",
       "31960   #sikh #templ vandalis #calgary, #wso condemn act   \n",
       "31961                                       thank follow   \n",
       "\n",
       "                                                Hashtags  \n",
       "0                                                   #run  \n",
       "1                         #lyft #disapointed #getthanked  \n",
       "2                                            No hashtags  \n",
       "3                                                 #model  \n",
       "4                                            #motivation  \n",
       "5                                        #allshowandnogo  \n",
       "6                                            No hashtags  \n",
       "7      #school #exams #hate #imagine #actorslife #rev...  \n",
       "8      #allin #cavs #champions #cleveland #clevelandc...  \n",
       "9                                                   #gr8  \n",
       "10                   #ireland #blog #silver #gold #forex  \n",
       "11     #orlando #standwithorlando #pulseshooting #orl...  \n",
       "12                                   #80days #gettingfed  \n",
       "13                                  #cnn #michigan #tcot  \n",
       "14     #australia #opkillingbay #seashepherd #helpcov...  \n",
       "15                                 #junior #yugyoem #omg  \n",
       "16                                   #thankful #positive  \n",
       "17                                           No hashtags  \n",
       "18                                     #friday! #cookies  \n",
       "19                                           No hashtags  \n",
       "20                                             #euro2016  \n",
       "21     #badday #coneofshame #cats #pissed #funny #laughs  \n",
       "22                                       #wine #weekend?  \n",
       "23                                           No hashtags  \n",
       "24     #tgif #ff #gamedev #indiedev #indiegamedev #sq...  \n",
       "25                   #upsideofflorida #shopalyssas #love  \n",
       "26     #smiles #media #pressconference #antalya #turk...  \n",
       "27                                                #ica16  \n",
       "28                                           No hashtags  \n",
       "29                                          #rip#orlando  \n",
       "...                                                  ...  \n",
       "31932                                        No hashtags  \n",
       "31933  #homophobic #freemilo #milo #freemilo #milo #f...  \n",
       "31934                                 #jcpenny #kentucky  \n",
       "31935                                        No hashtags  \n",
       "31936                                        No hashtags  \n",
       "31937                                        No hashtags  \n",
       "31938                                   #vijaysethupathi  \n",
       "31939                                         #friday!!!  \n",
       "31940                                        No hashtags  \n",
       "31941  #yay #love #pass #unistudent #photographystude...  \n",
       "31942                  #humpday #wednesday #kamp #ucsda|  \n",
       "31943                            #model #me #follow #emo  \n",
       "31944                                        No hashtags  \n",
       "31945            #dog #summer #hot #help #sun #day #more  \n",
       "31946                         #mailboxpride #liberalisme  \n",
       "31947                                        No hashtags  \n",
       "31948                                        No hashtags  \n",
       "31949  #youtube #original #music #song #relationship ...  \n",
       "31950                          #goldenretriever #animals  \n",
       "31951                          #secondlife #lonely #neko  \n",
       "31952                                        No hashtags  \n",
       "31953  #instagram #shower #water #berlin #berlincityg...  \n",
       "31954                                           #holiday  \n",
       "31955          #ibiza#bringiton#mallorca#holidays#summer  \n",
       "31956                                        No hashtags  \n",
       "31957                                        No hashtags  \n",
       "31958                                  #shame #imwithher  \n",
       "31959                                        No hashtags  \n",
       "31960                       #sikh #temple #calgary, #wso  \n",
       "31961                                        No hashtags  \n",
       "\n",
       "[31962 rows x 6 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(labels= ['id','Unnamed: 0','Hashtags'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunction. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit can't use caus offer wheelc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take time urd+-!!! dddd d|d|d|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: societi #motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      0   @user when a father is dysfunctional and is s...   \n",
       "1      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2      0                                bihday your majesty   \n",
       "3      0  #model   i love u take with u all the time in ...   \n",
       "4      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  father dysfunct selfish drag kid dysfunction. ...  \n",
       "1  thank #lyft credit can't use caus offer wheelc...  \n",
       "2                                     bihday majesti  \n",
       "3         #model love take time urd+-!!! dddd d|d|d|  \n",
       "4                         factsguide: societi #motiv  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunct selfish drag kid dysfunction. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit can't use caus offer wheelc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take time urd+-!!! dddd d|d|d|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: societi #motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      0   @user when a father is dysfunctional and is s...   \n",
       "1      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2      0                                bihday your majesty   \n",
       "3      0  #model   i love u take with u all the time in ...   \n",
       "4      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  father dysfunct selfish drag kid dysfunction. ...  \n",
       "1  thank #lyft credit can't use caus offer wheelc...  \n",
       "2                                     bihday majesti  \n",
       "3         #model love take time urd+-!!! dddd d|d|d|  \n",
       "4                         factsguide: societi #motiv  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       1\n",
       "14       1\n",
       "15       0\n",
       "16       0\n",
       "17       1\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       1\n",
       "24       0\n",
       "25       0\n",
       "26       0\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "31932    0\n",
       "31933    1\n",
       "31934    1\n",
       "31935    0\n",
       "31936    0\n",
       "31937    0\n",
       "31938    0\n",
       "31939    0\n",
       "31940    0\n",
       "31941    0\n",
       "31942    0\n",
       "31943    0\n",
       "31944    0\n",
       "31945    0\n",
       "31946    1\n",
       "31947    1\n",
       "31948    1\n",
       "31949    0\n",
       "31950    0\n",
       "31951    0\n",
       "31952    0\n",
       "31953    0\n",
       "31954    0\n",
       "31955    0\n",
       "31956    0\n",
       "31957    0\n",
       "31958    0\n",
       "31959    0\n",
       "31960    1\n",
       "31961    0\n",
       "Name: label, Length: 31962, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 1.0MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (probability.py, line 333)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/sanchita/.local/lib/python2.7/site-packages/nltk/probability.py\"\u001b[0;36m, line \u001b[0;32m333\u001b[0m\n\u001b[0;31m    print(\"%*s\" % (width, samples[i]), end=\" \")\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import unidecode\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "import operator \n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (probability.py, line 333)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/sanchita/.local/lib/python2.7/site-packages/nltk/probability.py\"\u001b[0;36m, line \u001b[0;32m333\u001b[0m\n\u001b[0;31m    print(\"%*s\" % (width, samples[i]), end=\" \")\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['clean_tweet']=df['tweet'].str.replace(\"@[\\w]*\",\"\")\n",
    "df['clean_tweet']=df['clean_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "df['clean_tweet']=df['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "tokenized_tweet = df['clean_tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet= tokenized_tweet.apply(lambda x: [WordNetLemmatizer().lemmatize(i) for i in x if i not in stop and len(i) > 2])\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i]= ' '.join(tokenized_tweet[i])\n",
    "                                        \n",
    "data['clean_tweet']= tokenized_tweet\n",
    "data.head()                                        \n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23971,), (7991,), (23971,), (7991,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['clean_tweet'].values,df['label'].values,random_state=42, stratify=df['label'].values)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-9e6cc660bba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbow_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanchita/.local/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanchita/.local/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanchita/.local/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                                tokenize)\n\u001b[1;32m    328\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 329\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanchita/.local/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    145\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "\n",
    "bow = bow_vectorizer.fit_transform(X_train)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6393"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanchita/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_temp['label'] = y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>i'm hungri #breakfast #kitchen gift#enjoy eat ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10813</th>\n",
       "      <td>pain nail like month</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>dad, best job i'v ever had!!! father day!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17662</th>\n",
       "      <td>#chickentrump jesz12: one #person' #disast ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>i'm excited!! can't wait see weekend memphis! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet  label\n",
       "7561   i'm hungri #breakfast #kitchen gift#enjoy eat ...      0\n",
       "10813                               pain nail like month      0\n",
       "1350         dad, best job i'v ever had!!! father day!!!      0\n",
       "17662  #chickentrump jesz12: one #person' #disast ano...      0\n",
       "4126   i'm excited!! can't wait see weekend memphis! ...      0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp.label[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonhate = X_temp[X_temp['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>i'm hungri #breakfast #kitchen gift#enjoy eat ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10813</th>\n",
       "      <td>pain nail like month</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>dad, best job i'v ever had!!! father day!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17662</th>\n",
       "      <td>#chickentrump jesz12: one #person' #disast ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>i'm excited!! can't wait see weekend memphis! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet  label\n",
       "7561   i'm hungri #breakfast #kitchen gift#enjoy eat ...      0\n",
       "10813                               pain nail like month      0\n",
       "1350         dad, best job i'v ever had!!! father day!!!      0\n",
       "17662  #chickentrump jesz12: one #person' #disast ano...      0\n",
       "4126   i'm excited!! can't wait see weekend memphis! ...      0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonhate.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = X_temp[X_temp.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonhatesample = nonhate.sample(n = hate.shape[0])    ##Sample narrow downing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>#late #ff #gamedev #indiedev #indiegamedev #sq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>could derrick rose never got hu alway haunt ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18459</th>\n",
       "      <td>girl take girl clearli bc they'r jealou sad pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>anoth angle. #ford #fordaustralia #fordfocusr ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>wholesome. #i_am #posit #affirm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet  label\n",
       "6876   #late #ff #gamedev #indiedev #indiegamedev #sq...      0\n",
       "2036   could derrick rose never got hu alway haunt ch...      0\n",
       "18459  girl take girl clearli bc they'r jealou sad pa...      0\n",
       "9928   anoth angle. #ford #fordaustralia #fordfocusr ...      0\n",
       "2726                     wholesome. #i_am #posit #affirm      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonhatesample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonhatesample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.concat([hate, nonhatesample], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31503</th>\n",
       "      <td>lost bet indi titl announc #xboxe3 sometim goo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28222</th>\n",
       "      <td>hunter #leafsa gather #draft2016 skill = #1 im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>i'm #grate - #affirm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>happi girl prettiest #vscocam #vscocamph #vsco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25588</th>\n",
       "      <td>look like anymore.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet  label\n",
       "31503  lost bet indi titl announc #xboxe3 sometim goo...      0\n",
       "28222  hunter #leafsa gather #draft2016 skill = #1 im...      0\n",
       "5428                                i'm #grate - #affirm      0\n",
       "1483   happi girl prettiest #vscocam #vscocamph #vsco...      0\n",
       "25588                                 look like anymore.      0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
